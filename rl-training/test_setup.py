"""
Quick test to verify RL setup before training
Run this first to catch issues early
"""
import sys

print("üß™ Testing RL Setup...")
print("=" * 50)

# Test 1: Import dependencies
print("\n1. Testing imports...")
try:
    import numpy as np
    print("   ‚úÖ numpy")
except ImportError as e:
    print(f"   ‚ùå numpy: {e}")
    sys.exit(1)

try:
    import torch
    print("   ‚úÖ torch")
    print(f"      Version: {torch.__version__}")
except ImportError as e:
    print(f"   ‚ùå torch: {e}")
    sys.exit(1)

# Test 2: GPU availability
print("\n2. Testing GPU...")
if torch.cuda.is_available():
    print(f"   ‚úÖ GPU Available")
    print(f"      Name: {torch.cuda.get_device_name(0)}")
    print(f"      Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
else:
    print("   ‚ö†Ô∏è  No GPU detected, will use CPU")
    print("      Training will be slower (~30-60 min instead of 15-25 min)")

# Test 3: Environment
print("\n3. Testing environment...")
try:
    from env import SwarmConstructionEnv
    env = SwarmConstructionEnv(num_agents=3, grid_size=8)
    obs = env.reset()
    print(f"   ‚úÖ Environment created")
    print(f"      Agents: {env.num_agents}")
    print(f"      Grid size: {env.grid_size}")
    print(f"      Observation size: {len(obs['agent_0'])}")
except Exception as e:
    print(f"   ‚ùå Environment: {e}")
    sys.exit(1)

# Test 4: Policy network
print("\n4. Testing policy network...")
try:
    from train import SimplePolicy
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    policy = SimplePolicy().to(device)
    
    # Test forward pass
    dummy_obs = torch.randn(1, 131).to(device)
    output = policy(dummy_obs)
    
    print(f"   ‚úÖ Policy network")
    print(f"      Device: {device}")
    print(f"      Parameters: {sum(p.numel() for p in policy.parameters())}")
except Exception as e:
    print(f"   ‚ùå Policy: {e}")
    sys.exit(1)

# Test 5: Quick episode
print("\n5. Testing episode execution...")
try:
    from train import train_episode
    
    optimizer = torch.optim.Adam(policy.parameters(), lr=0.001)
    reward, score = train_episode(env, policy, optimizer, device)
    
    print(f"   ‚úÖ Episode completed")
    print(f"      Reward: {reward:.2f}")
    print(f"      Match score: {score:.2%}")
except Exception as e:
    print(f"   ‚ùå Episode: {e}")
    sys.exit(1)

# Test 6: Target diversity
print("\n6. Testing target diversity...")
try:
    env = SwarmConstructionEnv(num_agents=3, grid_size=8)
    targets = []
    for _ in range(10):
        env.reset()
        targets.append(env.target.copy())
    
    # Check if targets are different
    unique = len(set([t.tobytes() for t in targets]))
    print(f"   ‚úÖ Target generation")
    print(f"      Unique targets in 10 resets: {unique}/10")
    if unique < 5:
        print("      ‚ö†Ô∏è  Low diversity - targets might be too similar")
except Exception as e:
    print(f"   ‚ùå Targets: {e}")

# Summary
print("\n" + "=" * 50)
print("‚úÖ Setup verified! Ready to train.")
print("\nStart training with:")
print("   ./train_gpu.sh")
print("or:")
print("   python train.py --episodes 500 --agents 5 --device cuda")
print()

